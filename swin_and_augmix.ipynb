{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "swin_and_augmix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1b64a6ba3fc498691c0f1d37f348a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b077f1e84674b4ba342f4a30b778236",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_162d128b18dc4547adce423d327e0cf4",
              "IPY_MODEL_916c8715f9094c5ab18ca5b7f49b1956",
              "IPY_MODEL_250a798b82364909b564817f8aba8582"
            ]
          }
        },
        "0b077f1e84674b4ba342f4a30b778236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "162d128b18dc4547adce423d327e0cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d679d5a652324e99a20caad4aaa41818",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90912494208743bd9c87dd0e535aaa6c"
          }
        },
        "916c8715f9094c5ab18ca5b7f49b1956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e494bfe02b514057bfaf1bd2c687f672",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2f00e2a9fd44852969f8c87d08422e7"
          }
        },
        "250a798b82364909b564817f8aba8582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0c16c1c964e43d5ac97c216e15de4fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1115/1115 [55:42&lt;00:00,  2.54s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f9126c573bf435fb1bc17dae7f47e0c"
          }
        },
        "d679d5a652324e99a20caad4aaa41818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90912494208743bd9c87dd0e535aaa6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e494bfe02b514057bfaf1bd2c687f672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2f00e2a9fd44852969f8c87d08422e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0c16c1c964e43d5ac97c216e15de4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f9126c573bf435fb1bc17dae7f47e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7285e8f50cc44b0583105b1e3a741341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1877aa7b1b54570907474e6a1e5f3e3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_09fd40245a59459ba17a097e91ac1f08",
              "IPY_MODEL_edd38b9b20ad48bca696ac0a9f98d75b",
              "IPY_MODEL_2f92c7a173f444a99769fb72c4b96177"
            ]
          }
        },
        "f1877aa7b1b54570907474e6a1e5f3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09fd40245a59459ba17a097e91ac1f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28df4439bde24a54af4730af0bc6dd33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35cc822903ac4e0d9204f2eb58564e0e"
          }
        },
        "edd38b9b20ad48bca696ac0a9f98d75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b295d73423944c98ad52007e87857af0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab0f9272dae8453f8ba514ba9e30d285"
          }
        },
        "2f92c7a173f444a99769fb72c4b96177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b304d300c1f42ef8401084f332ce535",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62/62 [56:27&lt;00:00,  1.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e872bd9d5b94d30b080fa24e82089bc"
          }
        },
        "28df4439bde24a54af4730af0bc6dd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35cc822903ac4e0d9204f2eb58564e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b295d73423944c98ad52007e87857af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab0f9272dae8453f8ba514ba9e30d285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b304d300c1f42ef8401084f332ce535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e872bd9d5b94d30b080fa24e82089bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NH0917/petfinder/blob/main/swin_and_augmix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcwdKqO43sqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f87bca4-dda2-4ae2-80f1-108db0d2c0f5"
      },
      "source": [
        "no = \"PetFineder\"\n",
        "description = \"ベンチーマーク_v3にAugmixを追加\"\n",
        "#swin_large_patch4_window7_224\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZHCySyWbFs7",
        "outputId": "38c1da31-de4b-40e1-8f17-565eafd2b0c6"
      },
      "source": [
        "!pip install timm\n",
        "!pip install albumentations==0.4.6\n",
        "!pip install transformers\n",
        "!pip install mlflow\n",
        "!pip install ttach"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.4.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (6.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.7/dist-packages (1.22.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from mlflow) (2018.9)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.18.7)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (5.0.3)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow) (21.3)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.1.24)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (3.17.3)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.16.2)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.1.4)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.7/dist-packages (from mlflow) (2.23.0)\n",
            "Requirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.19.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: alembic<=1.4.1 in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.3.0)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.7/dist-packages (from mlflow) (20.1.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow) (1.4.27)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow) (4.8.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (1.1.6)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic<=1.4.1->mlflow) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from docker>=4.0.0->mlflow) (1.2.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.17.3->mlflow) (2021.10.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow) (1.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->mlflow) (2.0.1)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.7/dist-packages (from gunicorn->mlflow) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mlflow) (3.0.6)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow) (0.12.0)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from albumentations.augmentations.transforms import ShiftScaleRotate\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import  matplotlib.pylab as plt\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import timm\n",
        "import os\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import gc\n",
        "import mlflow\n",
        "import shutil\n",
        "import torch.optim as optim\n",
        "from torch.optim import optimizer\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.adam import Adam\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "import ttach as tta\n",
        "from pandas.core.algorithms import value_counts\n",
        "import torchvision\n",
        "from PIL import Image, ImageOps, ImageEnhance"
      ],
      "metadata": {
        "id": "-gc6bWX-Opsf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYsv3ZZz6Bb8"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUAlaBJ_Y9dq"
      },
      "source": [
        "def int_parameter(level, maxval):\n",
        "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "    Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled to\n",
        "      level/PARAMETER_MAX.\n",
        "    Returns:\n",
        "    An int that results from scaling `maxval` according to `level`.\n",
        "    \"\"\"\n",
        "    return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
        "    Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled to\n",
        "      level/PARAMETER_MAX.\n",
        "    Returns:\n",
        "    A float that results from scaling `maxval` according to `level`.\n",
        "    \"\"\"\n",
        "    return float(level) * maxval / 10.\n",
        "\n",
        "\n",
        "def sample_level(n):\n",
        "    return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "    return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "    return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), 4)\n",
        "    return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "    degrees = int_parameter(sample_level(level), 30)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        degrees = -degrees\n",
        "    return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), 256)\n",
        "    return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 0.3)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform(pil_img.size,\n",
        "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 0.3)\n",
        "    if np.random.uniform() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform(pil_img.size,\n",
        "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
        "    if np.random.random() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform(pil_img.size,\n",
        "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "    level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
        "    if np.random.random() > 0.5:\n",
        "        level = -level\n",
        "    return pil_img.transform(pil_img.size,\n",
        "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def color(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def contrast(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def brightness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def sharpness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "augmentations = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y\n",
        "]\n",
        "\n",
        "augmentations_all = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, color, contrast, brightness, sharpness\n",
        "]\n",
        "\n",
        "def normalize(image):\n",
        "    \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
        "    return image - 127\n",
        "\n",
        "def apply_op(image, op, severity):\n",
        "    #   image = np.clip(image, 0, 255)\n",
        "    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
        "    pil_img = op(pil_img, severity)\n",
        "    return np.asarray(pil_img)\n",
        "\n",
        "def aug(image, preprocess,mixture_width,mixture_depth,aug_severity):\n",
        "  \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "  Args:\n",
        "    image: PIL.Image input image\n",
        "    preprocess: Preprocessing function which should return a torch tensor.\n",
        "  Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "  \"\"\"\n",
        "  aug_list = augmentations\n",
        "  \n",
        "  ws = np.float32(np.random.dirichlet([1] * mixture_width))\n",
        "  m = np.float32(np.random.beta(1, 1))\n",
        "\n",
        "  \n",
        "  mix = torch.zeros_like(preprocess(image=image)[\"image\"])\n",
        "  for i in range(mixture_width):\n",
        "    image_aug = image.copy().astype(np.uint8)\n",
        "    depth = mixture_depth if mixture_depth > 0 else np.random.randint(\n",
        "        1, 4)\n",
        "    for _ in range(depth):\n",
        "      op = np.random.choice(aug_list)\n",
        "      image_aug = apply_op(image_aug,op,aug_severity)\n",
        "\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * preprocess(image=image_aug)[\"image\"]\n",
        "\n",
        "  mixed = (1 - m) * preprocess(image=image)[\"image\"] + m * mix\n",
        "  return mixed\n",
        "\n",
        "class AugMixDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"Dataset wrapper to perform AugMix augmentation.\"\"\"\n",
        "\n",
        "  def __init__(self,dataset,preprocess, no_jsd=False,mixture_width=3,mixture_depth=10,aug_severity=10):\n",
        "    self.dataset = dataset\n",
        "    self.preprocess = preprocess\n",
        "    self.no_jsd = no_jsd\n",
        "    self.mixture_width = mixture_width\n",
        "    self.mixture_depth = mixture_depth\n",
        "    self.aug_severity = aug_severity\n",
        "\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    \n",
        "    img,label = self.dataset[i]\n",
        "  \n",
        "    if self.no_jsd:\n",
        "      return aug(img, self.preprocess,self.mixture_width,self.mixture_depth,self.aug_severity), label\n",
        "    else:\n",
        "      im_tuple = (self.preprocess(image=img)[\"image\"], aug(img, self.preprocess),\n",
        "                  aug(img, self.preprocess))\n",
        "  \n",
        "      return im_tuple, label\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "\n",
        "class petfinder(Dataset):\n",
        "    def __init__(self,df,data_dir,feature_col,transforms=False):\n",
        "        self.df = df\n",
        "        self.data_dir = data_dir\n",
        "        self.feature_col = feature_col\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_name = self.df[\"Id\"][idx]\n",
        "        img_path = os.path.join(self.data_dir,img_name) + str(\".jpg\")\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        label = self.df[\"Pawpularity\"][idx]\n",
        "        feature = self.df[self.feature_col].loc[idx].values\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)\n",
        "            img = img[\"image\"]\n",
        "\n",
        "            #img = img/255\n",
        "\n",
        "            #img = torch.tensor(img,dtype=torch.float)\n",
        "\n",
        "        else:\n",
        "            img\n",
        "        return img,label\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "4j68qZReOkEI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CFG\n",
        "def seed_everything(seed=42):\n",
        "    os.environ['PYTHONASSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "CFG = {\n",
        "    \"IMG_SIZE\":384,\n",
        "    \"batch_size\":8,\n",
        "    \"LR\":1e-5,\n",
        "    \"epochs\":50,\n",
        "    \"patience\":2,\n",
        "    \"MODEL_NAME\":\"swin_large_patch4_window12_384_in22k\",\n",
        "    \"pretrained\":True,\n",
        "    \"device\":\"cuda\",\n",
        "    \"nfolds\":10,\n",
        "    \"grad_accum_steps\":0,\n",
        "    \"use_amp\":True,\n",
        "    \"debug\":False\n",
        "}\n",
        "\n",
        "train_augmentation = A.Compose([\n",
        "                                 A.HorizontalFlip(p=0.5),  \n",
        "])\n",
        "\n",
        "test_augmentation = A.Compose([\n",
        "    A.Resize(CFG[\"IMG_SIZE\"],CFG[\"IMG_SIZE\"]),\n",
        "    A.Normalize([0.485,0.456,0.406],[0.229,00.224,0.225]),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "preprocess = test_augmentation"
      ],
      "metadata": {
        "id": "RC1O1vbpO9f0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data and define path\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/ColabNotebooks/kaggle/petfinder/data/input/train_skf10.csv\"\n",
        "data_dir = \"/content/drive/MyDrive/ColabNotebooks/kaggle/petfinder/data/input/train\"\n",
        "save_dir = \"/content/drive/MyDrive/ColabNotebooks/kaggle/petfinder/data/output\"\n",
        "mlflow_dir = \"/content/drive/MyDrive/ColabNotebooks/kaggle/petfinder/data/input/mlflow\"\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "train[\"Pawpularity\"] = train[\"Pawpularity\"]/100\n",
        "\n",
        "\n",
        "feature_col = [col for col in train.columns.tolist() if col not in [\"Id\",\"Pawpularity\",\"fold\"]]"
      ],
      "metadata": {
        "id": "L2nOSaqLPG6c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc8PdA4GaEwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604,
          "referenced_widgets": [
            "c1b64a6ba3fc498691c0f1d37f348a9c",
            "0b077f1e84674b4ba342f4a30b778236",
            "162d128b18dc4547adce423d327e0cf4",
            "916c8715f9094c5ab18ca5b7f49b1956",
            "250a798b82364909b564817f8aba8582",
            "d679d5a652324e99a20caad4aaa41818",
            "90912494208743bd9c87dd0e535aaa6c",
            "e494bfe02b514057bfaf1bd2c687f672",
            "e2f00e2a9fd44852969f8c87d08422e7",
            "f0c16c1c964e43d5ac97c216e15de4fc",
            "2f9126c573bf435fb1bc17dae7f47e0c",
            "7285e8f50cc44b0583105b1e3a741341",
            "f1877aa7b1b54570907474e6a1e5f3e3",
            "09fd40245a59459ba17a097e91ac1f08",
            "edd38b9b20ad48bca696ac0a9f98d75b",
            "2f92c7a173f444a99769fb72c4b96177",
            "28df4439bde24a54af4730af0bc6dd33",
            "35cc822903ac4e0d9204f2eb58564e0e",
            "b295d73423944c98ad52007e87857af0",
            "ab0f9272dae8453f8ba514ba9e30d285",
            "7b304d300c1f42ef8401084f332ce535",
            "5e872bd9d5b94d30b080fa24e82089bc"
          ]
        },
        "outputId": "89683ac0-ea74-4a57-b689-3ef4d1bd5fc4"
      },
      "source": [
        "#train and eval\n",
        "\n",
        "def loss_fn(y_hat,y_true):\n",
        "    y_hat = torch.sigmoid(y_hat) * 100\n",
        "    y_true = y_true*100\n",
        "    return torch.sqrt(torch.mean((y_hat-y_true)**2))\n",
        "\n",
        "class PetModel(nn.Module):\n",
        "    def __init__(self,cfg):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(CFG[\"MODEL_NAME\"],pretrained=CFG[\"pretrained\"])\n",
        "        self.model.head = nn.Linear(1536,1)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.model(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "def train_fn(train_progress_bar,model,loss_fn,device,optimizer,lr_scheduler,):\n",
        "    loss = 0\n",
        "    metrics = AverageMeter()\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    model.train()\n",
        "\n",
        "    for i,(img,labels) in enumerate(train_progress_bar):\n",
        "  \n",
        "        optimizer.zero_grad()\n",
        "        img = img.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=True):\n",
        "            outputs = model(img)\n",
        "            loss = criterion(outputs,labels)\n",
        "            rmse = loss_fn(outputs,labels)\n",
        "\n",
        "        metrics.update(rmse.item(),batch_size)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return metrics.avg\n",
        "\n",
        "def val_fn(val_progress_bar,model,loss_fn,device):\n",
        "    metrics = AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "\n",
        "    for i ,(img,labels) in enumerate(val_progress_bar):\n",
        "      img = img.to(device)\n",
        "      labels = labels.to(device)\n",
        "      batch_size = labels.size(0)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        outputs = model(img)\n",
        "      rmse = loss_fn(outputs,labels)\n",
        "      metrics.update(rmse.item(),batch_size)\n",
        "      outputs = torch.sigmoid(outputs) * 100\n",
        "      preds.append(outputs.cpu().numpy())\n",
        "\n",
        "      predictions = np.concatenate(preds)\n",
        "\n",
        "    return metrics.avg,predictions\n",
        "\n",
        "def train_loop(train_dl,val_dl,fold,cfg,val_df):\n",
        "      train_progress_bar = tqdm(train_dl)\n",
        "      val_progress_bar = tqdm(val_dl)\n",
        "      counter = 0\n",
        "\n",
        "      model = PetModel(cfg)\n",
        "      model.to(cfg[\"device\"])\n",
        "      \n",
        "      optimizer = torch.optim.AdamW(model.parameters(),lr=2e-5)\n",
        "      lr_scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=10*len(train_dl))\n",
        "      \n",
        "      for epoch in range(cfg[\"epochs\"]):\n",
        "          print(f\"{epoch}\")\n",
        "\n",
        "          train_rmse = train_fn(train_progress_bar,model,loss_fn,cfg[\"device\"],optimizer,lr_scheduler)\n",
        "          val_rmse,predict = val_fn(val_progress_bar,model,loss_fn,cfg[\"device\"])\n",
        "\n",
        "          print(f\"train_rmse is {train_rmse}\")\n",
        "          print(f\"val_rmse is {val_rmse}\")\n",
        "\n",
        "\n",
        "          if epoch == 0 or best_metric > val_rmse:\n",
        "              print(\"This epoch is best metric\")\n",
        "              if os.path.exists(save_dir):\n",
        "                  pass\n",
        "              else:\n",
        "                  os.mkdir(save_dir)\n",
        "              print(\"Save model\")\n",
        "              torch.save(model.state_dict(),os.path.join(save_dir,f\"model_state_fold_{fold}.pth\"))\n",
        "              best_metric = val_rmse\n",
        "              best_train_rmse = train_rmse\n",
        "\n",
        "              val_df[\"predict\"] = predict\n",
        "              val_df.to_csv(os.path.join(save_dir,f\"result_fold{fold}.csv\"),index=False)\n",
        "              print(\"Save df\")\n",
        "\n",
        "\n",
        "          else:\n",
        "              print(f\"Best metric == {best_metric:.6f} This Epoch metric == {val_rmse:.6f} So not Saving\")\n",
        "              counter += 1\n",
        "              print(f\"Counter is {counter}\")\n",
        "\n",
        "          if counter == CFG[\"patience\"]:\n",
        "              print(\"Early Stopping\")\n",
        "              break\n",
        "    \n",
        "      \n",
        "      return best_train_rmse,best_metric\n",
        "    \n",
        "\n",
        "def main(CFG):\n",
        "  \n",
        "  train_rmse_list = []\n",
        "  val_rmse_list = []\n",
        "\n",
        "  for fold in range(CFG[\"nfolds\"]):\n",
        "\n",
        "      print(f\"-\"*100)\n",
        "      print(f\"Start Fold{fold}\")\n",
        "      print(f\"UseCol{feature_col}\")\n",
        "        \n",
        "      train_idx,val_idx = train.query(f\"fold!={fold}\").index,train.query(f\"fold=={fold}\").index\n",
        "      train_df,val_df = train.loc[train_idx].reset_index(drop=True),train.loc[val_idx].reset_index(drop=True)\n",
        "      \n",
        "      if CFG[\"debug\"]:\n",
        "        print(\"This seccions is debug mode\")\n",
        "        train_df = train_df.loc[:100]\n",
        "        val_df = val_df.loc[:100]\n",
        "        CFG[\"epochs\"] = 1\n",
        "\n",
        "      \n",
        "      train_ds = petfinder(train_df,data_dir,feature_col,transforms=train_augmentation)\n",
        "      train_ds = AugMixDataset(train_ds, preprocess,True)\n",
        "      train_dl = DataLoader(train_ds,batch_size=CFG[\"batch_size\"],shuffle=True,num_workers=2,pin_memory=True,drop_last=True)\n",
        "      val_ds = petfinder(val_df,data_dir,feature_col,transforms=preprocess)\n",
        "      val_dl = DataLoader(val_ds,batch_size=CFG[\"batch_size\"]*2,shuffle=False,num_workers=2,pin_memory=True,drop_last=False)\n",
        "\n",
        "      train_rmse,val_rmse = train_loop(train_dl,val_dl,fold,CFG,val_df)\n",
        "      train_rmse_list.append(train_rmse)\n",
        "      val_rmse_list.append(val_rmse)\n",
        "\n",
        "      print(f\"End Fold{fold}\")\n",
        "      print(f\"-\"*100)\n",
        "\n",
        "  return train_rmse_list,val_rmse_list\n",
        "\n",
        "def ploting_and_output(total_loss_and_acc_list,save_dir):\n",
        "    \n",
        "    metrics_name = [\"train_loss\",\"valid_loss\"]\n",
        "\n",
        "    for i,metric in enumerate(metrics_name):\n",
        "        \n",
        "        fig,ax = plt.subplots()\n",
        "\n",
        "        ax.set_xlabel(\"Epoch\")\n",
        "        ax.set_xlabel(metric)\n",
        "\n",
        "        for j,metric_num in enumerate(total_loss_and_acc_list[i]):\n",
        "            ax.plot(range(len(metric_num)),metric_num,label=\"Fold_{}\".format(j))\n",
        "        plt.legend() \n",
        "        fig.savefig(os.path.join(save_dir,\"{}.png\".format(metric)))\n",
        "\n",
        "def save_mlflow(mlflow_dir,save_dir,total_loss_and_acc_list,cfg,desc,no):\n",
        "    \n",
        "    print(\"-\"*100)\n",
        "    dic1 = dict()\n",
        "    dic2 = dict()\n",
        "    train_acc_list_tmp = []\n",
        "    val_acc_list_tmp = []\n",
        "    train_acc_list,val_acc_list = total_loss_and_acc_list\n",
        "\n",
        "    for i,metric in enumerate(train_acc_list):\n",
        "        dic1[f\"train_rmse_fold{i}\"] = metric\n",
        "    mean_acc = np.mean(train_acc_list)\n",
        "    dic2[\"train_rmse_mean\"] = mean_acc\n",
        "    \n",
        "    for i,metric in enumerate(val_acc_list):\n",
        "        dic1[f\"val_rmse_fold{i}\"] = metric\n",
        "    mean_acc = np.mean(val_acc_list)\n",
        "    dic2[\"val_rmse_mean\"] = mean_acc\n",
        "        \n",
        "    mlflow.set_tracking_uri(mlflow_dir)\n",
        "    mlflow.set_experiment(no)\n",
        "    \n",
        "    with mlflow.start_run():\n",
        "        mlflow.log_params(cfg)\n",
        "        mlflow.log_metrics(dic1)\n",
        "        mlflow.log_metrics(dic2)\n",
        "        mlflow.log_artifact(save_dir)\n",
        "\n",
        "    print(\"save mlflow\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    total_loss_and_acc_list = main(CFG)\n",
        "    #ploting_and_output(total_loss_and_acc_list,save_dir)\n",
        "    save_mlflow(mlflow_dir,save_dir,total_loss_and_acc_list,CFG,description,no)\n",
        "    #shutil.copyfile(\"train.py\",os.path.join(save_dir,train.py))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Start Fold0\n",
            "UseCol['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1b64a6ba3fc498691c0f1d37f348a9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1115 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7285e8f50cc44b0583105b1e3a741341",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/62 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "train_rmse is 17.97657904636585\n",
            "val_rmse is 16.76389574243885\n",
            "This epoch is best metric\n",
            "Save model\n",
            "Save df\n",
            "1\n",
            "train_rmse is 17.097702233792006\n",
            "val_rmse is 16.63940547182849\n",
            "This epoch is best metric\n",
            "Save model\n",
            "Save df\n",
            "2\n",
            "train_rmse is 16.46861728116061\n",
            "val_rmse is 16.60896768795037\n",
            "This epoch is best metric\n",
            "Save model\n",
            "Save df\n",
            "3\n",
            "train_rmse is 15.412548155408158\n",
            "val_rmse is 16.676613635745277\n",
            "Best metric == 16.608968 This Epoch metric == 16.676614 So not Saving\n",
            "Counter is 1\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YWU9cNuzh0kP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}